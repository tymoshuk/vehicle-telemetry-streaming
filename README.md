# ğŸš— Vehicle Telemetry Streaming Pipeline with Medallion Architecture on GCP

This project demonstrates a real-time data pipeline for ingesting vehicle sensor telemetry using the **Vehicle Energy Dataset (VED)**. The pipeline follows the **Medallion architecture** pattern on **Google Cloud Platform (GCP)**, using modern cloud-native tools to ensure scalability, data quality, and analytics readiness.

## ğŸ§± Architecture Overview

```
Vehicle Energy Dataset (simulated IoT) 
      â†“
MQTT Broker (EMQX on GCP)
      â†“
Kafka (Confluent Cloud or GKE)
      â†“
Dataflow (Streaming ETL, watermarking)
      â†“
GCS (Bronze Layer - raw storage)
      â†“
Cloud Function trigger on new file
      â†“
Dataproc Serverless Spark (validation + transformation)
      â†“
Delta Lake on GCS (Silver/Gold layers, schema evolution)
      â†“
Dataflow (Batch)
      â†“
BigQuery (BI-ready analytics)
      â†“
Looker Dashboards
```

## ğŸ—ƒï¸ Dataset: Vehicle Energy Dataset (VED)

- Source: [gsoh/VED on GitHub](https://github.com/gsoh/VED)
- Format: CSV
- Contains:
  - Timestamped GPS and energy/fuel data
  - Speed, fuel level, auxiliary power, trip ID, etc.
- Simulates real-time vehicle telemetry for energy efficiency tracking.

## ğŸ“¦ GCP Services Used

| Service                | Purpose                                      |
|------------------------|----------------------------------------------|
| **Compute Engine / GKE** | Hosts MQTT broker (EMQX)                   |
| **Kafka**              | Buffering and event bus (Confluent or GKE)   |
| **Cloud Dataflow**     | Streaming ingestion + watermarking           |
| **Cloud Storage (GCS)**| Raw data lake storage (Bronze layer)         |
| **Cloud Functions**    | Triggers Delta ETL jobs on new file arrival  |
| **Dataproc Serverless**| Spark jobs for Silver/Gold Delta Lake ETL    |
| **Delta Lake**         | ACID-compliant data layers (Silver/Gold)     |
| **Dataproc Metastore** | Schema registration and catalog              |
| **BigQuery**           | BI-ready warehouse                           |
| **Looker**             | Data visualization & reporting               |

## ğŸ§ª Medallion Architecture Layers

### ğŸ¥‰ Bronze Layer (Raw)
- Data is written as-is from Kafka to GCS
- Format: JSON or Parquet
- No transformations or filtering applied
- Partitioned by `event_time`

### ğŸ¥ˆ Silver Layer (Validated & Cleaned)
- Spark job triggered by Cloud Function
- Performs:
  - Schema validation
  - Required field checks
  - Type coercion
  - Time parsing
- Written as **Delta Lake** format to GCS
- Registered in **Dataproc Metastore**

### ğŸ¥‡ Gold Layer (Curated & Aggregated)
- Optional second Spark job
- Aggregates trip-level KPIs
- Calculates metrics like average speed, fuel efficiency
- Output to **Delta Lake** and synced to **BigQuery**

## ğŸ§  Streaming Concepts Used

- **Watermarks** for late data handling
- **Tumbling windows** for time-based aggregations
- **Schema evolution** via Delta Lake auto-merge
- **Time travel** support for regulatory audits

## ğŸ›  Technologies

- `paho-mqtt` to simulate vehicle sensor messages
- EMQX MQTT broker
- Apache Kafka (Confluent Cloud or GKE)
- Apache Beam (via Cloud Dataflow)
- Apache Spark (Dataproc Serverless)
- Delta Lake (on GCS)
- Dataproc Metastore (Hive-compatible schema registry)
- BigQuery + Looker

## ğŸš€ How to Run

1. Simulate MQTT messages from VED dataset:
    ```bash
    python simulate_telemetry.py --input ved_sample.csv
    ```

2. Deploy EMQX broker on GCP VM or GKE
3. Set up Kafka with EMQX plugin
4. Deploy Dataflow streaming job â†’ GCS /bronze/
5. Deploy Cloud Function trigger for new files
6. Spark job â†’ Delta Lake (Silver)
7. (Optional) Spark â†’ Gold
8. Batch Dataflow job â†’ BigQuery
9. Build Looker dashboards

## ğŸ“Š Sample KPIs in Looker

- Average fuel efficiency per trip
- Speed profiles over time
- Idle time vs drive time ratio
- Energy loss across sessions

## ğŸ§  Why This Matters

This architecture is inspired by real-world use cases in:
- Fleet management
- Smart mobility
- EV energy optimization
- Automotive telemetry and analytics

It follows best practices in:
- **GCP data architecture**
- **Delta Lake schema governance**
- **Streaming analytics**
- **Serverless orchestration**

## ğŸ“‚ License & Credits

- Dataset: [Vehicle Energy Dataset (VED)](https://github.com/gsoh/VED) â€“ MIT License
- Inspired by the Medallion architecture (Databricks)